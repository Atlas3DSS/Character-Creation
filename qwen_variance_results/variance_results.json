{
  "baseline": {
    "runs": [
      {
        "run": 1,
        "open_sarcasm_pct": 0.0,
        "open_assistant_pct": 0.0,
        "math_accuracy": 0.9,
        "knowledge_accuracy": 0.8,
        "timestamp": "2026-02-19T04:32:21"
      },
      {
        "run": 2,
        "open_sarcasm_pct": 0.12,
        "open_assistant_pct": 0.0,
        "math_accuracy": 0.9,
        "knowledge_accuracy": 0.8,
        "timestamp": "2026-02-19T04:43:29"
      },
      {
        "run": 3,
        "open_sarcasm_pct": 0.0,
        "open_assistant_pct": 0.0,
        "math_accuracy": 0.8,
        "knowledge_accuracy": 0.8,
        "timestamp": "2026-02-19T04:52:16"
      },
      {
        "run": 4,
        "open_sarcasm_pct": 0.04,
        "open_assistant_pct": 0.0,
        "math_accuracy": 0.8,
        "knowledge_accuracy": 0.8,
        "timestamp": "2026-02-19T05:02:25"
      },
      {
        "run": 5,
        "open_sarcasm_pct": 0.04,
        "open_assistant_pct": 0.0,
        "math_accuracy": 0.9,
        "knowledge_accuracy": 0.8,
        "timestamp": "2026-02-19T05:13:17"
      }
    ],
    "mean_sarcasm": 0.04,
    "std_sarcasm": 0.049,
    "ci95_sarcasm": [
      -0.0208,
      0.1008
    ],
    "mean_assistant": 0.0,
    "std_assistant": 0.0,
    "ci95_assistant": [
      0.0,
      0.0
    ],
    "mean_math": 0.86,
    "std_math": 0.0548,
    "ci95_math": [
      0.792,
      0.928
    ],
    "mean_knowledge": 0.8,
    "std_knowledge": 0.0,
    "ci95_knowledge": [
      0.8,
      0.8
    ]
  },
  "v4_only": {
    "runs": [
      {
        "run": 1,
        "open_sarcasm_pct": 0.92,
        "open_assistant_pct": 0.0,
        "math_accuracy": 0.8,
        "knowledge_accuracy": 0.8,
        "timestamp": "2026-02-19T05:23:41"
      },
      {
        "run": 2,
        "open_sarcasm_pct": 0.88,
        "open_assistant_pct": 0.0,
        "math_accuracy": 0.7,
        "knowledge_accuracy": 0.8,
        "timestamp": "2026-02-19T05:34:26"
      },
      {
        "run": 3,
        "open_sarcasm_pct": 0.92,
        "open_assistant_pct": 0.0,
        "math_accuracy": 0.8,
        "knowledge_accuracy": 0.8,
        "timestamp": "2026-02-19T05:45:08"
      },
      {
        "run": 4,
        "open_sarcasm_pct": 0.88,
        "open_assistant_pct": 0.0,
        "math_accuracy": 0.7,
        "knowledge_accuracy": 0.8,
        "timestamp": "2026-02-19T05:55:48"
      },
      {
        "run": 5,
        "open_sarcasm_pct": 0.92,
        "open_assistant_pct": 0.0,
        "math_accuracy": 0.9,
        "knowledge_accuracy": 0.8,
        "timestamp": "2026-02-19T06:06:44"
      }
    ],
    "mean_sarcasm": 0.904,
    "std_sarcasm": 0.0219,
    "ci95_sarcasm": [
      0.8768,
      0.9312
    ],
    "mean_assistant": 0.0,
    "std_assistant": 0.0,
    "ci95_assistant": [
      0.0,
      0.0
    ],
    "mean_math": 0.78,
    "std_math": 0.0837,
    "ci95_math": [
      0.6761,
      0.8839
    ],
    "mean_knowledge": 0.8,
    "std_knowledge": 0.0,
    "ci95_knowledge": [
      0.8,
      0.8
    ]
  },
  "reverse_L15_a10": {
    "runs": [
      {
        "run": 1,
        "open_sarcasm_pct": 0.04,
        "open_assistant_pct": 0.0,
        "math_accuracy": 0.9,
        "knowledge_accuracy": 0.8,
        "timestamp": "2026-02-19T06:18:25"
      },
      {
        "run": 2,
        "open_sarcasm_pct": 0.04,
        "open_assistant_pct": 0.0,
        "math_accuracy": 0.9,
        "knowledge_accuracy": 0.8,
        "timestamp": "2026-02-19T06:30:06"
      },
      {
        "run": 3,
        "open_sarcasm_pct": 0.04,
        "open_assistant_pct": 0.0,
        "math_accuracy": 0.9,
        "knowledge_accuracy": 0.8,
        "timestamp": "2026-02-19T06:41:44"
      },
      {
        "run": 4,
        "open_sarcasm_pct": 0.08,
        "open_assistant_pct": 0.0,
        "math_accuracy": 1.0,
        "knowledge_accuracy": 0.8,
        "timestamp": "2026-02-19T06:53:19"
      },
      {
        "run": 5,
        "open_sarcasm_pct": 0.04,
        "open_assistant_pct": 0.0,
        "math_accuracy": 1.0,
        "knowledge_accuracy": 0.8,
        "timestamp": "2026-02-19T07:04:48"
      }
    ],
    "mean_sarcasm": 0.048,
    "std_sarcasm": 0.0179,
    "ci95_sarcasm": [
      0.0258,
      0.0702
    ],
    "mean_assistant": 0.0,
    "std_assistant": 0.0,
    "ci95_assistant": [
      0.0,
      0.0
    ],
    "mean_math": 0.94,
    "std_math": 0.0548,
    "ci95_math": [
      0.872,
      1.008
    ],
    "mean_knowledge": 0.8,
    "std_knowledge": 0.0,
    "ci95_knowledge": [
      0.8,
      0.8
    ]
  },
  "v4_reverse_L15_a10": {
    "runs": [
      {
        "run": 1,
        "open_sarcasm_pct": 0.16,
        "open_assistant_pct": 0.0,
        "math_accuracy": 0.9,
        "knowledge_accuracy": 0.8,
        "timestamp": "2026-02-19T07:16:25"
      },
      {
        "run": 2,
        "open_sarcasm_pct": 0.2,
        "open_assistant_pct": 0.0,
        "math_accuracy": 1.0,
        "knowledge_accuracy": 0.8,
        "timestamp": "2026-02-19T07:28:01"
      },
      {
        "run": 3,
        "open_sarcasm_pct": 0.28,
        "open_assistant_pct": 0.0,
        "math_accuracy": 1.0,
        "knowledge_accuracy": 0.9,
        "timestamp": "2026-02-19T07:39:38"
      },
      {
        "run": 4,
        "open_sarcasm_pct": 0.2,
        "open_assistant_pct": 0.0,
        "math_accuracy": 1.0,
        "knowledge_accuracy": 0.8,
        "timestamp": "2026-02-19T07:51:23"
      },
      {
        "run": 5,
        "open_sarcasm_pct": 0.32,
        "open_assistant_pct": 0.0,
        "math_accuracy": 1.0,
        "knowledge_accuracy": 0.9,
        "timestamp": "2026-02-19T08:03:10"
      }
    ],
    "mean_sarcasm": 0.232,
    "std_sarcasm": 0.0657,
    "ci95_sarcasm": [
      0.1504,
      0.3136
    ],
    "mean_assistant": 0.0,
    "std_assistant": 0.0,
    "ci95_assistant": [
      0.0,
      0.0
    ],
    "mean_math": 0.98,
    "std_math": 0.0447,
    "ci95_math": [
      0.9245,
      1.0355
    ],
    "mean_knowledge": 0.84,
    "std_knowledge": 0.0548,
    "ci95_knowledge": [
      0.772,
      0.908
    ]
  },
  "v4_L18_27_a10": {
    "runs": [
      {
        "run": 1,
        "open_sarcasm_pct": 0.32,
        "open_assistant_pct": 0.0,
        "math_accuracy": 1.0,
        "knowledge_accuracy": 0.9,
        "timestamp": "2026-02-19T08:14:46"
      },
      {
        "run": 2,
        "open_sarcasm_pct": 0.48,
        "open_assistant_pct": 0.0,
        "math_accuracy": 0.9,
        "knowledge_accuracy": 0.9,
        "timestamp": "2026-02-19T08:26:19"
      },
      {
        "run": 3,
        "open_sarcasm_pct": 0.48,
        "open_assistant_pct": 0.0,
        "math_accuracy": 1.0,
        "knowledge_accuracy": 0.9,
        "timestamp": "2026-02-19T08:37:42"
      },
      {
        "run": 4,
        "open_sarcasm_pct": 0.28,
        "open_assistant_pct": 0.0,
        "math_accuracy": 1.0,
        "knowledge_accuracy": 0.9,
        "timestamp": "2026-02-19T08:49:17"
      },
      {
        "run": 5,
        "open_sarcasm_pct": 0.32,
        "open_assistant_pct": 0.0,
        "math_accuracy": 0.8,
        "knowledge_accuracy": 0.8,
        "timestamp": "2026-02-19T09:00:46"
      }
    ],
    "mean_sarcasm": 0.376,
    "std_sarcasm": 0.0963,
    "ci95_sarcasm": [
      0.2564,
      0.4956
    ],
    "mean_assistant": 0.0,
    "std_assistant": 0.0,
    "ci95_assistant": [
      0.0,
      0.0
    ],
    "mean_math": 0.94,
    "std_math": 0.0894,
    "ci95_math": [
      0.829,
      1.051
    ],
    "mean_knowledge": 0.88,
    "std_knowledge": 0.0447,
    "ci95_knowledge": [
      0.8245,
      0.9355
    ]
  },
  "donut_control_a12": {
    "runs": [
      {
        "run": 1,
        "open_sarcasm_pct": 0.16,
        "open_assistant_pct": 0.0,
        "math_accuracy": 0.2,
        "knowledge_accuracy": 0.1,
        "timestamp": "2026-02-19T09:12:25"
      },
      {
        "run": 2,
        "open_sarcasm_pct": 0.12,
        "open_assistant_pct": 0.0,
        "math_accuracy": 0.3,
        "knowledge_accuracy": 0.1,
        "timestamp": "2026-02-19T09:23:59"
      },
      {
        "run": 3,
        "open_sarcasm_pct": 0.16,
        "open_assistant_pct": 0.0,
        "math_accuracy": 0.2,
        "knowledge_accuracy": 0.0,
        "timestamp": "2026-02-19T09:35:24"
      },
      {
        "run": 4,
        "open_sarcasm_pct": 0.08,
        "open_assistant_pct": 0.0,
        "math_accuracy": 0.2,
        "knowledge_accuracy": 0.2,
        "timestamp": "2026-02-19T09:46:57"
      },
      {
        "run": 5,
        "open_sarcasm_pct": 0.12,
        "open_assistant_pct": 0.0,
        "math_accuracy": 0.3,
        "knowledge_accuracy": 0.0,
        "timestamp": "2026-02-19T09:58:26"
      }
    ],
    "mean_sarcasm": 0.128,
    "std_sarcasm": 0.0335,
    "ci95_sarcasm": [
      0.0865,
      0.1695
    ],
    "mean_assistant": 0.0,
    "std_assistant": 0.0,
    "ci95_assistant": [
      0.0,
      0.0
    ],
    "mean_math": 0.24,
    "std_math": 0.0548,
    "ci95_math": [
      0.172,
      0.308
    ],
    "mean_knowledge": 0.08,
    "std_knowledge": 0.0837,
    "ci95_knowledge": [
      -0.0239,
      0.1839
    ]
  }
}